"use strict";(self.webpackChunkuuboyscy_engineering_logs=self.webpackChunkuuboyscy_engineering_logs||[]).push([[6586],{33099:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>u,contentTitle:()=>i,default:()=>g,frontMatter:()=>s,metadata:()=>n,toc:()=>l});var n=t(54458),a=t(74848),r=t(28453);const s={slug:"from-mapreduce-to-spark-the-evolution-of-big-data-processing",title:"From MapReduce to Spark: The Evolution of Big Data Processing",authors:["uuboyscy"],tags:["hadoop","spark"]},i="From MapReduce to Spark: The Evolution of Big Data Processing",u={authorsImageUrls:[void 0]},l=[{value:"1. Introduction: Big Data Challenges",id:"1-introduction-big-data-challenges",level:2}];function c(e){const o={h2:"h2",p:"p",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(o.h2,{id:"1-introduction-big-data-challenges",children:"1. Introduction: Big Data Challenges"}),"\n",(0,a.jsx)(o.p,{children:"Big data means working with very large amounts of information. In one of my jobs, I had to handle 500TB of data and run more than 10,000 SQL queries every day. The old system we used was slow and had many problems, like some tasks taking over 24 hours to finish. In this blog, I will share how I solved these problems by using Spark and making the system faster and better."})]})}function g(e={}){const{wrapper:o}={...(0,r.R)(),...e.components};return o?(0,a.jsx)(o,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28453:(e,o,t)=>{t.d(o,{R:()=>s,x:()=>i});var n=t(96540);const a={},r=n.createContext(a);function s(e){const o=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),n.createElement(r.Provider,{value:o},e.children)}},54458:e=>{e.exports=JSON.parse('{"permalink":"/zh-Hant/blog/from-mapreduce-to-spark-the-evolution-of-big-data-processing","source":"@site/i18n/zh-Hant/docusaurus-plugin-content-blog/2022-08-23-from-mapreduce-to-spark-the-evolution-of-big-data-processing/index.md","title":"From MapReduce to Spark: The Evolution of Big Data Processing","description":"1. Introduction: Big Data Challenges","date":"2022-08-23T00:00:00.000Z","tags":[{"inline":false,"label":"Hadoop","permalink":"/zh-Hant/blog/tags/hadoop","description":"Hadoop tag description"},{"inline":false,"label":"Spark","permalink":"/zh-Hant/blog/tags/spark","description":"Spark tag description"}],"readingTime":3.365,"hasTruncateMarker":true,"authors":[{"name":"uuboyscy","title":"Data Engineer | Founder of uuboyscy.dev","url":"https://uuboyscy.dev","page":{"permalink":"/zh-Hant/blog/authors/uuboyscy"},"socials":{"github":"https://github.com/uuboyscy","linkedin":"https://www.linkedin.com/in/chengyou-shi/"},"imageURL":"https://github.com/uuboyscy.png","key":"uuboyscy"}],"frontMatter":{"slug":"from-mapreduce-to-spark-the-evolution-of-big-data-processing","title":"From MapReduce to Spark: The Evolution of Big Data Processing","authors":["uuboyscy"],"tags":["hadoop","spark"]},"unlisted":false,"prevItem":{"title":"From Airflow to Prefect: Choosing the Right Orchestration Tool for Your Workflow","permalink":"/zh-Hant/blog/from-airflow-to-prefect-choosing-the-right-orchestration-tool-for-your-workflow"},"nextItem":{"title":"Welcome","permalink":"/zh-Hant/blog/welcome"}}')}}]);